temp <- read.csv(filenames[i])
data <- rbind(data, temp)
}
mean(data[ , pollutant], na.rm = T)
}
pollutantmean("specdata", "sulfate", 1:10)
pollutantmean("specdata", "nitrate", 70:72)
pollutantmean("specdata", "nitrate", 23)
pollutantmean("specdata", "nitrate", 70:72)
debug(pollutantmean)
pollutantmean("specdata", "nitrate", 70:72)
temp <- read.csv("hw1_data.csv")
n <- complete.cases(temp)
sum(n)
temp[n]
temp[n, ]
setwd("D:/Documents/Coursera/Data Science/3. Getting and Cleaning Data")
x <- "Hello world!"
rm(x)
dir.create("test")
file.exists("test")
checkmakedir <- function(dirname){
if(file.exists(dirname)){
message("Directory already exists")
}
else {dir.create(dirname)}
}
checkmakedir("test")
checkmakedir("hello")
wd <- getwd()
download.file()
?download.file
wd
download.file(url = fileurl, destfile =  "D:/Documents/Coursera/Data Science/3. Getting and Cleaning Data/camea.csv",
method = "curl")
fileurl <- "https://data.baltimorecity.gov/api/views/dz54-2aru/rows.csv?accessType=DOWNLOAD"
download.file(url = fileurl, destfile =  "D:/Documents/Coursera/Data Science/3. Getting and Cleaning Data/camea.csv",
method = "curl")
?read.data
?read.table
ls()
list.files
list.files()
cameradata <- read.table("camera.csv", header = T)
cameradata <- read.table("camera.csv",sep = ",", header = T)
cameradata <- read.table("camea.csv", header = T)
cameradata <- read.table("camea.csv", sep = ",",  header = T)
head(cameradata)
?read.table
cameradata <- read.table(file= "camea.csv", sep = ", ", header = T, skip = 5, nrows = 10)
cameradata <- read.table(file= "camea.csv", sep = ",", header = T, skip = 5, nrows = 10)
cameradata
fieurl <- "https://data.baltimorecity.gov/api/views/dz54-2aru/rows.csv?accessType=DOWNLOAD&bom=true&format=true"
download.file(url = fileurl, destfile = "camera.xlsx", method = "curl")
fileurl <- "https://data.baltimorecity.gov/api/views/dz54-2aru/rows.csv?accessType=DOWNLOAD&bom=true&format=true"
download.file(url = fileurl, destfile = "camera.xlsx", method = "curl")
list.files()
library(xlxs)
library(xlsx)
install.packages(xlsx)
install.packages("xlsx")
install.packages("xlsx package")
library(xlsx)
library('xlsx')
library(xlsx)
installed.packages()
install.packages("xlsx package")
install.packages("xlsx")
library(xlsx)
install.packages("xlsx")
load(xlsx)
library(xlsx)
library('xlsx')
?library
library(xlsxjars)
library(xlsx)
library()
library(xlsx)
library('xlsx')
library('C:/Users/EliteBook/Documents/R/win-library/3.5/xlsx')
library('xlsx')
install.packages(xlsx)
install.packages('xlsx')
library(xlsx)
source(xlsx)
?source
options(java.home="C:\Program Files\Java\jre1.8.0_25")
Sys.setenv(JAVA_HOME='C:\\Program Files (x86)\\Java\\jre7')
library(xlsx)
Sys.setenv(JAVA_HOME='C:\\Program Files\\Java\\jre7')
library(xlsx)
?read.xlsx
cameradata <- read.xlsx(file= 'camera.xlsx', sheetIndex = 1)
cameradata <- read.xlsx(file= 'camera.xlsx', sheetIndex = 1, header = T)
cameradata <- read.xlsx("camera.xlsx", sheetIndex = 1)
download.file(url = "https://data.baltimorecity.gov/api/views/dz54-2aru/rows.csv?accessType=DOWNLOAD&bom=true&format=true",
destfile = "cameras.xlsx")
cameradata <- read.xlsx(file = "cameras.xlsx", sheetIndex = 1, header = T)
?read.xlsx
library(xlsx)
?read.xlsx
cameradata <- read.xlsx(file = "cameras.xlsx", sheetIndex = 1)
cameradatasub <- read.xlsx(file = "cameras.xlsx", sheetIndex = 1,
colIndex = 2:6, rowIndex = 1:10, header = T)
cameradatasub
library(XML)
install.packages(XML)
install.packages('XML')
library(XML)
list(XML)
doc <- xmlTreeParse("https://www.w3schools.com/xml/simple.xml", useInternal = T)
doc <- xmlTreeParse("https://www.w3schools.com/xml/simple.xml")
doc <- xmlTreeParse("https://www.w3schools.com/xml/simple.xml", useInternalNodes = T)
?xmlTreeParse
doc <- xmlTreeParse(file ="https://www.w3schools.com/xml/simple.xml", useInternalNodes = T)
fileurl <- "https://www.w3schools.com/xml/simple.xml"
doc <- xmlTreeParse(fileurl)
doc <- xmlTreeParse("food.xml")
do
doc
?xmlRoot
rootnode <- xmlroot(doc)
rootnode <- xmlRoot(doc)
rootnode
xmlName(rootnode)
names(rootnode)
rootnodee[[1]]
rootnode[[1]]
rootnode[3]
rootnode[[3]]
rootnode[[1]][[3]]
rootnode[[3]][[1]]
?xmlValue
xmlSApply(rootnode, xmlValue)
?xmlSApply
xmlApply(rootnode, xmlValue)
?xpathSApply
xpathSApply(rootnode, "//name", xmlvalue)
xpathSApply(rootnode, "//name", xmlValue)
xpathSApply(rootnode, "//name", xmlValue)
doc <- xmlTreeParse("food.xml")
rootnode <- xmlRoot(doc)
warnings()
xmlSApply(rootnode, xmlValue)
rootnode[[1]][[3]]
rootnode[[3]][[1]]
, "//
xpathSApply(rootnode, "//name", xmlValue)
xpathSApply(rootnode, "//price", xmlValue)
doc <- xmlTreeParse("https://www.w3schools.com/xml/simple.xml")
fileurl <- "http://www.espn.in/nfl/team/_/name/bal/baltimore-ravens"
doc <- htmlTreeParse(fileurl)
teams <- xpathSApply(doc, "//li[@class= 'team-name']", xmlValue)
teams <- xpathSApply(doc,"//li[@class= 'team-name']", xmlValue)
teams <- xpathSApply(doc,"//li[@class= 'team-name']", xmlValue)
scores <- xpathSApply(doc,"//li[@class= 'score']", xmlValue)
rootnode <- xmlRoot(doc)
scores <- xpathSApply(rootnode,"//li[@class= 'score']", xmlValue)
doc <- htmlTreeParse(fileurl)
scores <- xpathSApply(doc,"//li[@class= 'score']", xmlValue)
doc <- htmlTreeParse(fileurl, useInternalNodes = T)
scores <- xpathSApply(doc,"//li[@class= 'score']", xmlValue) ##error, not excecuting
scorea
scores
doc <- htmlTreeParse(fileurl, useInternalNodes = T)
teams <- xpathSApply(doc,"//li[@class= 'team-name']", xmlValue) ##error, not excecuting
teams
doc <- htmlTreeParse(fileurl, useInternal = T)
scores <- xpathSApply(doc,"//li[@class= 'score']", xmlValue) ##error, not excecuting
teams <- xpathSApply(doc,"//li[@class= 'team-name']", xmlValue) ##error, not excecuting
teams
scores
scores <- xpathSApply(doc,"//li[@class= 'score']", xmlValue) ##error, not excecuting
doc <- htmlTreeParse(fileurl)
scores <- xpathSApply(doc,"//li[@class= 'score']", xmlValue) ##error, not excecuting
teams <- xpathSApply(doc,"//li[@class= 'team-name']", xmlValue) ##error, not excecuting
, useInternal = T
doc <- htmlTreeParse(fileurl, useInternal = T)
doc <- htmlTreeParse(fileurl, useInternalNodes = T)
scores <- xpathSApply(doc,"//li[@class= 'score']", xmlValue) ##error, not excecuting
teams <- xpathSApply(doc,"//li[@class= 'team-name']", xmlValue) ##error, not excecuting
teams
scores
doc <- htmlTreeParse(fileurl, useInternal = T)
scores <- xpathSApply(doc,"//li[@class= 'score']", xmlValue) ##error, not excecuting
teams <- xpathSApply(doc,"//li[@class= 'team-name']", xmlValue) ##error, not excecuting
teams
scores
fileurl <- "http://www.espn.go.com/nfl/team/_/name/bal/baltimore-ravens"
doc <- htmlTreeParse(fileurl, useInternal = T)
scores <- xpathSApply(doc,"//li[@class= 'score']", xmlValue) ##error, results different than lectures
teams <- xpathSApply(doc,"//li[@class= 'team-name']", xmlValue) ##same
teams
scores
ranking <- xpathSApply(doc,"//li[@class= 'ranking']", xmlValue) ##same
ranking
xpathSApply(doc,"//li[@class= 'record']", xmlValue) ##same
xpathSApply(doc,"//li[@class= 'sub']", xmlValue) ##same
xpathSApply(doc,"//li[@class= 'user']", xmlValue) ##same
xpathSApply(doc,"//li[@class= 'tier-3']", xmlValue) ##same
xpathSApply(doc,"//li[@class= 'nextGame']", xmlValue) ##same
fileurl <- "http://www.espn.com/nfl/team/roster/_/name/bal/baltimore-ravens"
doc <- htmlTreeParse(fileurl, useInternal = T)
xpathSApply(doc, "//li[@class= 'name'", xmlValue)
xpathSApply(doc, "//li[@class= 'name']", xmlValue)
xpathSApply(doc, "//li[@class= 'active']", xmlValue)
xpathSApply(doc, "//li[@class= 'search']", xmlValue)
xpathSApply(doc, "//li[@class= 'user']", xmlValue)
xpathSApply(doc, "//li[@class= 'pillar fantasy']", xmlValue)
xpathSApply(doc, "//li[@class= 'pillar listen']", xmlValue)
xpathSApply(doc, "//li[@class= 'sub']", xmlValue)
library(swirl)
swril()
swirl()
install_from_swirl("Getting and Cleaning Data")
bye()
head(iris)
library(jsonlite)
myjson <- toJSON(iris, pretty = T`)
)
99(())
(())
)
)]}
}}}{{{{{}}}}}}}}}}}}}
library(jsonlite)
myjson <- toJSON(iris, pretty = TRUE)
myjson
cat(myjson)
cat(myjson)
rm(list = ls())
mtcars
mtcars[mtcars$cyl == 4, ]
mtcars[mtcars$mpg == 22.8, ]
housing <- read.csv("housing.csv")
housing[housing$VAL ==24, ]
head(housing$VAL, 200)
values <- housing$VAL
values[values==24]
na.omit(values[values==24])
class(na.omit(values[values==24]))
nrows(housing[housing$VAL == 24, ])
nrow(housing[housing$VAL == 24, ])
## the answer was wrong, so I printed
housing[housing$VAL == 24 && housing$VAL== !is.na, ]
## the answer was wrong, so I printed
housing[housing$VAL == 24 && housing$VAL== !is.na, ]
## the answer was wrong, so I printed
housing[housing$VAL == 24 & housing$VAL== !is.na, ]
## the answer was wrong, so I printed
housing[(housing$VAL == 24 & housing$VAL== !is.na), ]
## the answer was wrong, so I printed
housing[(housing$VAL == 24 && housing$VAL== !is.na), ]
nrow(mtcars[mtcars$cyl == 4, ])
nrow(mtcars[mtcars$cyl == 4, ])
mtcars[mtcars$cyl == 4, ]
rm(values)
download.file(url = "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FDATA.gov_NGAP.xlsx",
destfile = "ngap.xlsx")
library(xlsx)
doc <- read.xlsx("ngap.xlsx", sheetIndex = 1, nrow(18:23), ncol(7:15))
?read.xlsx
row
doc <- read.xlsx("ngap.xlsx", sheetIndex = 1, rowIndex =  18:23, colIndex =  7:15)
doc <- read.xlsx("ngap.xlsx", sheetIndex = 1, rowIndex =  18:23, colIndex =  7:15)
download.file(url = "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FDATA.gov_NGAP.xlsx",
destfile = "ngap.xlsx", method = 'wb')
download.file(url = "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FDATA.gov_NGAP.xlsx",
destfile = "ngap.xlsx", mode = 'wb')
doc <- read.xlsx("ngap.xlsx", sheetIndex = 1, rowIndex =  18:23, colIndex =  7:15)
sum(dat$Zip*dat$Ext,na.rm=T)
dat <- read.xlsx("ngap.xlsx", sheetIndex = 1, rowIndex =  18:23, colIndex =  7:15)
sum(dat$Zip*dat$Ext,na.rm=T)
download.file(url = "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml",
destfile = "brest.xml")
library(xml)
library(XML)
doc <- xmlTreeParse("brest.xml")
doc <- xmlTreeParse("brest.xml", useInternal = T)
doc <- xmlTreeParse("brest.xml")
xmlName(doc)
doc <- xmlTreeParse("brest.xml", useInternalNodes = T)
xmlName(doc)
names(doc)
doc <- xmlTreeParse("brest.xml")
names(doc)
xmlValue(doc)
doc <- xmlTreeParse("brest.xml", useInternalNodes = T)
names(doc)
xmlValue(doc)
doc[[1]]
rootdoc <- xmlRoot(doc)
names(rootdoc)
rootdoc[[1]]
rootdoc[[1]]
names(rootdoc)
rootdoc[[1]][[1]]
xmlSApply(rootdoc[[1]], xmlValue)
xmlSApply(rootdoc, xmlValue)
xpathSApply(rootdoc, "//zipcode" = 21231, xmlValue)
xpathSApply(rootdoc, "//zipcode" = "21231", xmlValue)
xpathSApply(rootdoc, "//zipcode", xmlValue)
xpathSApply(rootdoc, "//zipcode = 21231", xmlValue)
xpathSApply(rootdoc, "//zipcode = 21231", sum)
xpathSApply(rootdoc, "//zipcode = "21231"", xmlValue)
sum(xpathSApply(rootdoc, "//zipcode", xmlValue) = "21231")
sum(xpathSApply(rootdoc, "//zipcode", xmlValue) == "21231")
(xpathSApply(rootdoc, "//zipcode" == "21231", xmlValue)
xpathSApply(rootdoc, "//zipcode" == "21231", xmlValue)
xpathSApply(rootdoc, "//zipcode" == "21231", xmlValue)
xpathSApply(rootdoc, "//zipcode == "21231"", xmlValue)
?fread
library()
library(data.table)
?fread
download.file(url = "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv",
destfile = "house.csv")
download.file(url = "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv",
destfile = "house.csv")
download.file(url = "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv",
destfile = "house.csv")
DT <- fread("house.csv")
system.time(DT[,mean(pwgtp15), by= SEX])
system.time(DT[,mean(pwgtp15),by=SEX]
)
system.time(sapply(split(DT$pwgtp15,DT$SEX),mean))
system.time(mean(DT[DT$SEX==1,]$pwgtp15); mean(DT[DT$SEX==2,] $pwgtp15))
nrow(subset(housing, VAL == 24))
install.packages('RMySQL')
library(RMySQL)
ucscdb <- dbConnect(MySQL(), user = "genome",
host = "genome-mysql.soe.ucsc.edu")
rm(list = ls())
ucscdb <- dbConnect(MySQL(), user = "genome",
host = "genome-mysql.soe.ucsc.edu")
ucscdb
?dbConnect
result <- dbGetQuery(ucscdb, "show databases;")
result <- dbGetQuery(ucscdb, "show databases;"); dbDisconnect(uscsdb)
result <- dbGetQuery(ucscdb, "show databases;"); dbDisconnect(uscsdb);
ucscdb <- dbConnect(MySQL(), user = "genome",
host = "genome-mysql.soe.ucsc.edu")
result <- dbGetQuery(ucscdb, "show databases;"); dbDisconnect(uscsdb)
rm(list = ls(
))
source('D:/Documents/Coursera/Data Science/3. Getting and Cleaning Data/scribbling w2.R', echo=TRUE)
dbDisconnect(uscsdb)
source('D:/Documents/Coursera/Data Science/3. Getting and Cleaning Data/scribbling w2.R', echo=TRUE)
result
hg19 <- dbConnect(MySQL(), user = "genome", db = "hg19"
host = "genome-mysql.soe.ucsc.edu")
hg19 <- dbConnect(MySQL(), user = "genome", db = "hg19" ,
host = "genome-mysql.soe.ucsc.edu")
first <- hg19[1]
alltables <- dbListTables(hg19)
alltables[1:5]
dbListFields(hg19, "HInv")
dbGetQuery((hg19, "select count(*) from HInv"))
dbGetQuery((hg19, "select count(*) from HInv")
dbGetQuery(hg19, "select count(*) from HInv")
HInv <- dbReadTable(hg19, "HInv")
head(HInv)
library(RMySQL)
install.packages(data.table)
install.packages('data.table')
library(data.table)
library(jsonlite)
source('http://bioconductor.org/biocLite.R')
biocLite('rhdf5')
library(xlsx)
## Reading from the web
con = url('https://scholar.google.com.pk/citations?user=ffQSH1MAAAAJ&hl=en')
htmlcode <- readLines(con)
close(con)
url <- 'https://scholar.google.com.pk/citations?user=ffQSH1MAAAAJ&hl=en'
install.packages('html')
library(XML)
htmlabuji <- htmlTreeParse(url, useInternalNodes = T  )
xpathSApply(htmlabuji, '//title', xmlValue)
rootabuji <- xmlRoot(htmlabuji)
xpathSApply(htmlabuji, '//title', xmlValue)
htmlabuji <- htmlTreeParse(url, useInternalNodes = T  )
htmlabuji[[1]][[1]]
rootabuji[[1]][[1]]
rootabuji[[1]]
rootabuji
xpathSApply(rootabuji, '//p', xmlValue)
xpathSApply(htmlabuji, '//p', htmlvalue)
xpathSApply(htmlabuji, '/', xmlValue)
xpathSApply(htmlabuji, '/node', xmlValue)
xpathSApply(htmlabuji, '/sd', xmlValue)
xpathSApply(htmlabuji, '//citations', xmlValue)
xpathSApply(htmlabuji, '//', xmlValue)
xpathSApply(rootabuji, '/html', xmlValue)
xpathSApply(htmlabuji, '/html', xmlValue)
xpathSApply(htmlabuji, '//title', xmlValue)
xpathSApply(htmlabuji, '//meta@name', xmlValue)
xpathSApply(htmlabuji, '//m', title', xmlValue)
xpathSApply(htmlabuji, '//title' ,xmlValue)
xpathSApply(htmlabuji, '//html' ,xmlValue)
xpathSApply(htmlabuji, '//head' ,xmlValue)
xpathSApply(htmlabuji, '//body' ,xmlValue)
xpathSApply(rootabuji, '//body' ,xmlValue)
xpathSApply(htmlabuji, '//body' ,xmlValue)
xpathSApply(htmlabuji, '//title' ,xmlValue)
htmlabuji <- htmlTreeParse(url, useInternal= T  )
htmlabuji <- htmlTreeParse(url, useInternal = T  )
xpathSApply(htmlabuji, '//title' ,xmlValue) ## not giving the desired result
xpathSApply(htmlabuji, '//td[@id='col-citedby']')
xpathSApply(htmlabuji, '//td[@id='col-citedby']', xmlValue)
xpathSApply(htmlabuji, "//td[@id='col-citedby']", xmlValue)
unlist(xpathSApply(htmlabuji, '//title' ,xmlValue)) ## not giving the desired result
unlist(xpathSApply(htmlabuji, '//title' ,xmlValue)) ## not giving the desired result
unlist(xpathSApply(htmlabuji, "//td[@id='col-citedby']", xmlValue)) ## again not the result
## Reading from the web
con = url('https://scholar.google.com.pk/citations?user=ffQSH1MAAAAJ&hl=en')
htmlcode <- readLines(con)
close(con)
htmlabuji <- htmlTreeParse(htmlcode, useInternalNodes = T)
xpathSApply(htmlabuji, '//title' ,xmlValue) ## not giving the desired result
rm(list = ls())
## Reading from the web
con = url('https://scholar.google.com.pk/citations?user=ffQSH1MAAAAJ&hl=en')
htmlcode <- readLines(con)
#Now this is working
htmlabuji <- htmlTreeParse(htmlcode, useInternalNodes = T)
xpathSApply(htmlabuji, '/node' , xmlValue)
unlist(xpathSApply(htmlabuji, '/node' , xmlValue))
xpathSApply(htmlabuji, '/html' , xmlValue)
htmlabuji[[1]]
rootabuji <- xmlRoot(htmlabuji)
rootabuji[[1]]
names(rootabuji[[1]])
names(rootabuji)
names(rootabuji[[1]])
names(rootabuji[[1]][[1]])
names(rootabuji[[1]][[11]])
names(rootabuji[[2]])
names(rootabuji[[2]][[1]])
#using xpath
xpathSApply(htmlabuji, '/title' , xmlValue)
#using xpath
xpathSApply(htmlabuji, '//title' , xmlValue)
#using xpath
xpathSApply(htmlabuji, '//td' , xmlValue)
#using xpath
xpathSApply(htmlabuji, "//td" , xmlValue)
#using xpath
xpathSApply(htmlabuji, "//td[id]" , xmlValue)
#using xpath
xpathSApply(htmlabuji, "//td[id@col-citedby]" , xmlValue)
#using xpath
xpathSApply(htmlabuji, "//td[id@'col-citedby']" , xmlValue)
#using xpath
xpathSApply(htmlabuji, "//td[id@'col-citedby']" , xmlValue)
#using xpath
xpathSApply(htmlabuji, "//td[id@'col-citedby']" , xmlValue)
#using xpath
xpathSApply(htmlabuji, "//td[id@'col-citedby']", xmlValue)
names(rootabuji[[2]][[1]])
#using xpath
xpathSApply(htmlabuji, "//title", xmlValue)
#using xpath
xpathSApply(htmlabuji, "//td", xmlValue)
## Reading from the web
con = url('https://scholar.google.com.pk/citations?user=ffQSH1MAAAAJ&hl=en')
htmlcode <- readLines(con)
close(con)
#Now this is working
htmlabuji <- htmlTreeParse(htmlcode, useInternalNodes = T)
#for subsetting
rootabuji <- xmlRoot(htmlabuji)
## Reading from the web
library(XML)
con = url('https://scholar.google.com.pk/citations?user=ffQSH1MAAAAJ&hl=en')
htmlcode <- readLines(con)
close(con)
#Now this is working
htmlabuji <- htmlTreeParse(htmlcode, useInternalNodes = T)
#for subsetting
rootabuji <- xmlRoot(htmlabuji)
rootabuji[[1]]
names(rootabuji[[2]][[1]])
#using xpath
xpathSApply(htmlabuji, "//title", xmlValue)
xpathSApply(rootabuji, "//title", xmlValue)
## Reading from the web
library(XML)
con = url('https://scholar.google.com.pk/citations?user=ffQSH1MAAAAJ&hl=en')
htmlcode <- readLines(con)
close(con)
#Now this is working
htmlabuji <- htmlTreeParse(htmlcode, useInternalNodes = T)
#for subsetting
rootabuji <- xmlRoot(htmlabuji)
#using xpath
xpathSApply(htmlabuji, "//title", xmlValue)
xpathSApply(htmlabuji, "//td[@id]", xmlValue)
xpathSApply(htmlabuji, "//td[@id='col-citedby']", xmlValue)
unlist(xpathSApply(htmlabuji, "//td[@id='col-citedby']", xmlValue))
xpathSApply(htmlabuji, "//td", xmlValue)
class(xpathSApply(htmlabuji, "//td", xmlValue))
xpathSApply(htmlabuji, "//td[@id = 'col-citedby']", xmlValue)
xpathSApply(htmlabuji, "//td[@class]", xmlValue)
xpathSApply(htmlabuji, "//a[@class = 'gcs_a_at']", xmlValue)
xpathSApply(htmlabuji, "//a[@class = 'gsc_a_at']", xmlValue)
xpathSApply(htmlabuji, "html/head/title", xmlValue)
xpathSApply(htmlabuji, "html//head//title", xmlValue)
xpathSApply(htmlabuji, "html/head/title", xmlValue)
#using httr package
install.packages('httr')
library(httr)
